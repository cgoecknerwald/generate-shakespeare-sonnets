
\newif\ifshowsolutions
\showsolutionstrue
\input{preamble}
\newcommand{\boldline}[1]{\underline{\textbf{#1}}}

\usepackage{graphicx}
\graphicspath{ {images/} }

\chead{%
  {\vbox{%
      \vspace{2mm}
      \large
      Machine Learning \& Data Mining \hfill
      Caltech CS/CNS/EE 155 \hfill \\[1pt]
      Miniproject 2\hfill
      Released February $17^{th}$, 2017 \\
    }
  }
}

\begin{document}
\pagestyle{fancy}

% LaTeX is simple if you have a good template to work with! To use this document, simply fill in your text where we have indicated. To write mathematical notation in a fancy style, just write the notation inside enclosing $dollar signs$.

% For example:
% $y = x^2 + 2x + 1$

% For help with LaTeX, please feel free to see a TA!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\medskip
\begin{itemize}

    \item \boldline{Group members:} Enrico Borba, Claire Goeckner-Wald
    \item \boldline{Team name:} Papa Mart's Mini Gary - The Comeback
    \item \boldline{Division of labour:}
        Enrico Borba: Programming, ideas, report visualization.
        Claire Goeckner-Wald: Programming, ideas, report assembly.

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Pre-processing}
\medskip
\begin{itemize}
    % Explain your choices, as well why you chose these choices initially. What was your final pre-processing? How did you tokenize your words, and split up the data into separate sequences? What changed as you continued on your project? What did you try that didn’t work? Also write about any analysis you did on the dataset to help you make these decisions.

    %%%%%%%%%%%%%%%%%%%%%%
    \item \boldline{Handling the dataset}
    \begin{itemize}
        \item \textbf{Quatrains versus couplets:} Initially, we thought that we should train two different models, one on lines from the quatrains, and one on lines from the couplets. This way, we could more accurately capture the ``shift in tone'' that Shakespeare often performs during his sonnets. However, since we decided to `force' rhyming using a rhyming dictionary garnered from the dataset, we ended up combining quatrains and couplets into one model.
        \item \textbf{Punctuation:} we stripped the following punctuation from the sonnet data
    \end{itemize}
    \item \boldline{The dictionary}
    \begin{itemize}
        \item \textbf{Reason for use:} We used a dictionary to assign each word a unique number. We had to set all word to lowercase first, to avoid using ``The'' in the middle of a sentence, when we would rather have ``the''.
        \item \textbf{Unexpected trouble:} The use of the dictionary is also one reason why we decided to treat lines from quatrains and couplets equally. Initially, we had one large dictionary that covered all words Shakespeare used in the dataset. As expected, some words were used only in the couplets, or only in the quatrains. However, we ran into errors when training two separate Hidden Markov Models, most likely because the model expected that if we gave it words (represented by numbers) $\{ 3, 15, 23, 14, 194\}$, that there would be $(1-194)$ states available. However, this was not the case.
    \end{itemize}


\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Unsupervised Learning}
\medskip
\begin{itemize}
    % Your report should also contain a section highlighting your HMM. What packages did you use, if any? How did you choose the number of hidden states?

    %%%%%%%%%%%%%%%%%%%%%%
    \item \boldline{HMM}

    \begin{itemize}
    \item \textbf{Naive poem generation:}
    \item \textbf{Package:}
    \item \textbf{Number of hidden states:}
    \end{itemize}


\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Visualization \& Interpretation}
\medskip
\begin{itemize}
    % In your report, you should explain your interpretation of how a Hidden Markov Model learns patterns in Shakespeare’s texts. You should briefly elaborate on the methods you used to analyze the model. In addition, for at least 5 hidden states give a list of the top 10 words that associate with this hidden state and state any common features these groups. Furthermore, try to interpret and visualize the learned transitions between states. A possible suggestion is to draw a transition diagram of your markov model and give de- scriptive names to the sates. Feel free to be creative with your visualizations, but remember that accurately representing data is still your primary objective. Your figures, tables, and diagrams should contribute to a discussion about your model.

    %%%%%%%%%%%%%%%%%%%%%%

    \item \boldline{Interpretations}

    \begin{itemize}
    \item \textbf{Analyzing the model:}
        We tokenized the sonnets by words, removing punctuation. Because of
        this, the HMM can only determine patterns between words. Thus,
        the 6 HMM states have some complex pattern between the words,
        unlikely to be too related to the English grammar. \\
    \item \textbf{Imagery:}
        The below image shows the 6 states and their transitions. Each state
        is colored to show directed transitions. That is, since state 1 is
        yellow, all yellow transitions come from state 1. More transparent
        transitions show lesser probabilities. So, the nearly opaque transition
        from state 1 to state 5 is of comparitively high probability. Also,
        the transitions are drawn in order of their probabilities. So, if
        some transition $a$ appears above transition $b$, the transition $a$
        has higher probability than transition $b$. \\

        Furthermore, we have the top 10 words for each state represented
        next to the states. However, we disallow repititions of words in
        the image. If a word appears next to a state, then that state was
        the state that was most likely to emmit it.
    \end{itemize}

    \begin{center}
        \includegraphics[scale=.4]{states.png}
    \end{center}

    \pagebreak

    \begin{itemize}
    \item \textbf{State Analysis:}
        We notice that state 1 has a high collection of verbs. This continues
        as well: checking the top 20 words for state 1 yields ``are, may, was,
        should, say, did, must, know, might, away'', which is further composed
        mostly of verbs. \\

        State 1 has the highest probability of transitioning to state 5, which
        contains mainly prepositions and some nouns (which correctly follow
        from verbs). \\

        State 5 has the highest probability of transitioning to state 3, which
        has several possesive nouns. Inspecting the top 20 words of state 3
        yields more possesive nouns such as ``her, thine, our'', and also
        some adjectives. \\

        State 3 then has the highest probability of transitioning to state 4,
        which contains even more nouns, as the sentence at this point, if
        began at state 3 (a likely verb), should reach the noun the verb is
        modifying. \\

        State 4 then has similar probabilities of transitioning to states 1
        and 0, which allow for more compound phrases. Since the HMM mainly
        trained on single lines of the sonnets, taking more than 9 transitions
        almost guarantees a grammerless phrase. The average number of words
        per line in all of the sonnets is just over 8, thus the HMM has
        difficulty outputing coherent long phrases.
    \end{itemize}

\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Poetry Generation}
\medskip
\begin{itemize}
    % In your report, describe your algorithm for generating the 14 line sonnet. Include at least one sonnet generated from your unsupervized trained HMM in your final report as an example. You should comment on the quality of geneating poems in this naive manner. How is the accurate is rhyme, rythym, and syllable count to what a sonnet should be? Do your poems make any sense? Does it retain Shakespeare’s original voice? How does training with different number of hidden states effect the poems generated (in a qualita- tive manner)? For the good qualities that you describe, also discuss how you think the HMM was able to capture these qualities.

    %%%%%%%%%%%%%%%%%%%%%%
    \item \boldline{Algorithm}

    \begin{itemize}
    \item \textbf{Example sonnet:}
    \item \textbf{Quality of poem:}
    \end{itemize}


\end{itemize}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Additional Goals}
\medskip
\begin{itemize}
    % Talk about the extra improvements you made to your poem generation algorithm. What was the prob- lems you were trying to fix? How did you go about attempting to fix it? Why did you think that what you tried would work? Did your method succeed in making the sonnet more like a sonnet? If not, why do you think what you tried didn’t work? What tradeoffs do you see in quality and creativity when you make these changes?

    %%%%%%%%%%%%%%%%%%%%%%
    \item \boldline{Topic}

    \begin{itemize}
    \item \textbf{Subtopic:}
    \item \textbf{Subtopic:}
    \end{itemize}

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Extra Credit: Recurrent Neural Networks}
\medskip
\begin{itemize}
    %Explain in detail what model you implemented using what packages. What parameters did you tune? How does an RNN/LSTM compare in poem quality to the HMM? How does it compare in runtime/amount of training data needed to the HMM? Include a poem that you generated using your recurrent model.

    %%%%%%%%%%%%%%%%%%%%%%
    \item \boldline{Topic}

    \begin{itemize}
    \item \textbf{Subtopic:}
    \item \textbf{Subtopic:}
    \end{itemize}

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}